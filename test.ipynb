{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4306a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas读写csv文件\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def log_print(*arg, log=True):\n",
    "    if log:\n",
    "        print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n",
    "              *arg,\n",
    "              flush=True)\n",
    "\n",
    "\n",
    "path = '/Users/mingjue/downloads/'\n",
    "\n",
    "df_train_1 = pd.read_csv(path + 'data_format1/train_format1.csv', dtype={'user_id': 'str', 'merchant_id': 'str', 'label': 'float'})\n",
    "df_test_1 = pd.read_csv(path + 'data_format1/test_format1.csv', dtype={'user_id': 'str', 'merchant_id': 'str', 'label': 'float'})\n",
    "df_user_info = pd.read_csv(path + 'data_format1/user_info_format1.csv', dtype='str')\n",
    "df_user_log = pd.read_csv(path + 'data_format1/user_log_format1.csv', dtype='str')\n",
    "df_train_2 = pd.read_csv(path + 'data_format2/train_format2.csv', dtype='str')\n",
    "df_test_2 = pd.read_csv(path + 'data_format2/test_format2.csv', dtype='str')\n",
    "df_infer = pd.read_csv(path + 'sample_submission.csv', dtype='str')\n",
    "\n",
    "# df_user_info\n",
    "# age_range 和 gender 有缺失值\n",
    "# age_range 的取值为0-8，0表示缺失值（age_range一般对应年龄大小顺序，根据分布判断0表示未知）\n",
    "# gender 的取值为0-2，2表示缺失值(根据官网描述，2和NULL表示未知)\n",
    "# 将df_user_info的 age_range 列  字段转换为float， 取值0都替换为空值,\n",
    "df_user_info['age_range'] = df_user_info['age_range'].astype(float)\n",
    "df_user_info['age_range'] = df_user_info['age_range'].replace(0, np.nan)\n",
    "# 将df_user_info的 gender 列 中 取值为2替换为空值\n",
    "df_user_info['gender'] = df_user_info['gender'].replace('2', np.nan)\n",
    "\n",
    "# df_user_log\n",
    "df_user_log.rename(columns={'seller_id': 'merchant_id'}, inplace=True)\n",
    "# time_stamp 的取值为0511到1112共186天，表示mmdd，没有年份，请转换为标准日期格式\n",
    "df_user_log['time_stamp'] = pd.to_datetime('2025' + df_user_log['time_stamp'], format='%Y%m%d')\n",
    "df_user_log['recency'] = (pd.to_datetime('2025-11-12') - df_user_log['time_stamp']).dt.days + 1\n",
    "\n",
    "# 计算用户rfm, 数据没有monetary，所以不能计算rfm，只能计算rf\n",
    "# recency：距离最后一次消费的天数\n",
    "# frequency：消费的次数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4908e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-13 16:58:43.543946 df_user_rf shape: (424170, 7)\n",
      "2025-10-13 17:01:12.638821 df_user_rf_0 shape: (423862, 7)\n",
      "2025-10-13 17:01:14.177730 df_user_rf_1 shape: (31044, 7)\n",
      "2025-10-13 17:01:22.688616 df_user_rf_2 shape: (424170, 7)\n",
      "2025-10-13 17:01:29.348064 df_user_rf_3 shape: (233428, 7)\n",
      "2025-10-13 17:01:29.885844 df_user_rf shape: (424170, 31)\n",
      "2025-10-13 17:03:49.311226 df_user_merchant_rf shape: (14058666, 7)\n",
      "2025-10-13 17:05:58.476718 df_user_merchant_rf_0 shape: (13263204, 7)\n",
      "2025-10-13 17:06:00.088527 df_user_merchant_rf_1 shape: (62236, 7)\n",
      "2025-10-13 17:06:07.756090 df_user_merchant_rf_2 shape: (2209433, 7)\n",
      "2025-10-13 17:06:13.484044 df_user_merchant_rf_3 shape: (1972052, 7)\n",
      "2025-10-13 17:06:33.234049 df_user_merchant_rf shape: (14058666, 27)\n",
      "2025-10-13 17:09:37.837622 df_merchant shape: (4995, 7)\n",
      "2025-10-13 17:12:30.219396 df_merchant_0 shape: (4995, 7)\n",
      "2025-10-13 17:12:31.650152 df_merchant_1 shape: (4729, 7)\n",
      "2025-10-13 17:12:39.664247 df_merchant_2 shape: (4995, 7)\n"
     ]
    }
   ],
   "source": [
    "df_user_rf = df_user_log.groupby('user_id').agg(\n",
    "    r=('recency', 'min'),\n",
    "    f=('user_id', 'count'), \n",
    "    f_item=('item_id', 'nunique'),\n",
    "    f_cat=('cat_id', 'nunique'), \n",
    "    f_merchant=('merchant_id', 'nunique'),\n",
    "    f_brand=('brand_id', 'nunique'),\n",
    ").reset_index()\n",
    "log_print('df_user_rf shape:', df_user_rf.shape)\n",
    "df_user_rf_0 = df_user_log.query('\"0\"==action_type').groupby('user_id').agg(\n",
    "    r_0=('recency', 'min'),\n",
    "    f_0=('user_id', 'count'), \n",
    "    f_item_0=('item_id', 'nunique'),\n",
    "    f_cat_0=('cat_id', 'nunique'), \n",
    "    f_merchant_0=('merchant_id', 'nunique'),\n",
    "    f_brand_0=('brand_id', 'nunique'),\n",
    ").reset_index() \n",
    "log_print('df_user_rf_0 shape:', df_user_rf_0.shape)\n",
    "df_user_rf_1 = df_user_log.query('\"1\"==action_type').groupby('user_id').agg(\n",
    "    r_1=('recency', 'min'),\n",
    "    f_1=('user_id', 'count'), \n",
    "    f_item_1=('item_id', 'nunique'),\n",
    "    f_cat_1=('cat_id', 'nunique'), \n",
    "    f_merchant_1=('merchant_id', 'nunique'),\n",
    "    f_brand_1=('brand_id', 'nunique'),\n",
    ").reset_index()\n",
    "log_print('df_user_rf_1 shape:', df_user_rf_1.shape)\n",
    "df_user_rf_2 = df_user_log.query('\"2\"==action_type').groupby('user_id').agg(\n",
    "    r_2=('recency', 'min'),\n",
    "    f_2=('user_id', 'count'), \n",
    "    f_item_2=('item_id', 'nunique'),\n",
    "    f_cat_2=('cat_id', 'nunique'), \n",
    "    f_merchant_2=('merchant_id', 'nunique'),\n",
    "    f_brand_2=('brand_id', 'nunique'),\n",
    ").reset_index() \n",
    "log_print('df_user_rf_2 shape:', df_user_rf_2.shape)\n",
    "df_user_rf_3 = df_user_log.query('\"3\"==action_type').groupby('user_id').agg(\n",
    "    r_3=('recency', 'min'),\n",
    "    f_3=('user_id', 'count'), \n",
    "    f_item_3=('item_id', 'nunique'),\n",
    "    f_cat_3=('cat_id', 'nunique'), \n",
    "    f_merchant_3=('merchant_id', 'nunique'),\n",
    "    f_brand_3=('brand_id', 'nunique'),\n",
    ").reset_index()\n",
    "log_print('df_user_rf_3 shape:', df_user_rf_3.shape)\n",
    "df_user_rf = df_user_rf.merge(\n",
    "    df_user_rf_0, how='left', on='user_id',\n",
    ").merge(\n",
    "    df_user_rf_1, how='left', on='user_id',\n",
    ").merge(\n",
    "    df_user_rf_2, how='left', on='user_id',\n",
    ").merge(\n",
    "    df_user_rf_3, how='left', on='user_id',\n",
    ")\n",
    "log_print('df_user_rf shape:', df_user_rf.shape)\n",
    "del df_user_rf_0, df_user_rf_1, df_user_rf_2, df_user_rf_3,\n",
    "# 计算 user_id, merchant_id 交互特征\n",
    "df_user_merchant_rf = df_user_log.groupby(['user_id', 'merchant_id']).agg(\n",
    "    r_um=('recency', 'min'),\n",
    "    f_um=('user_id', 'count'),\n",
    "    f_item_um=('item_id', 'nunique'),\n",
    "    f_cat_um=('cat_id', 'nunique'),\n",
    "    f_brand_um=('brand_id', 'nunique'),\n",
    ").reset_index()\n",
    "log_print('df_user_merchant_rf shape:', df_user_merchant_rf.shape)\n",
    "df_user_merchant_rf_0 = df_user_log.query('\"0\"==action_type').groupby(['user_id', 'merchant_id']).agg(\n",
    "    r_um_0=('recency', 'min'),\n",
    "    f_um_0=('user_id', 'count'),        \n",
    "    f_item_um_0=('item_id', 'nunique'), \n",
    "    f_cat_um_0=('cat_id', 'nunique'),   \n",
    "    f_brand_um_0=('brand_id', 'nunique'),       \n",
    ").reset_index()\n",
    "log_print('df_user_merchant_rf_0 shape:', df_user_merchant_rf_0.shape)\n",
    "df_user_merchant_rf_1 = df_user_log.query('\"1\"==action_type').groupby(['user_id', 'merchant_id']).agg(\n",
    "    r_um_1=('recency', 'min'),\n",
    "    f_um_1=('user_id', 'count'),        \n",
    "    f_item_um_1=('item_id', 'nunique'), \n",
    "    f_cat_um_1=('cat_id', 'nunique'),   \n",
    "    f_brand_um_1=('brand_id', 'nunique'),           \n",
    ").reset_index()\n",
    "log_print('df_user_merchant_rf_1 shape:', df_user_merchant_rf_1.shape)\n",
    "df_user_merchant_rf_2 = df_user_log.query('\"2\"==action_type').groupby(['user_id', 'merchant_id']).agg(\n",
    "    r_um_2=('recency', 'min'),\n",
    "    f_um_2=('user_id', 'count'),        \n",
    "    f_item_um_2=('item_id', 'nunique'), \n",
    "    f_cat_um_2=('cat_id', 'nunique'),   \n",
    "    f_brand_um_2=('brand_id', 'nunique'),           \n",
    ").reset_index()\n",
    "log_print('df_user_merchant_rf_2 shape:', df_user_merchant_rf_2.shape)\n",
    "df_user_merchant_rf_3 = df_user_log.query('\"3\"==action_type').groupby(['user_id', 'merchant_id']).agg(\n",
    "    r_um_3=('recency', 'min'),\n",
    "    f_um_3=('user_id', 'count'),        \n",
    "    f_item_um_3=('item_id', 'nunique'), \n",
    "    f_cat_um_3=('cat_id', 'nunique'),   \n",
    "    f_brand_um_3=('brand_id', 'nunique'),               \n",
    ").reset_index()\n",
    "log_print('df_user_merchant_rf_3 shape:', df_user_merchant_rf_3.shape)\n",
    "df_user_merchant_rf = df_user_merchant_rf.merge(\n",
    "    df_user_merchant_rf_0, how='left', on=['user_id', 'merchant_id'],\n",
    ").merge(\n",
    "    df_user_merchant_rf_1, how='left', on=['user_id', 'merchant_id'],\n",
    ").merge(\n",
    "    df_user_merchant_rf_2, how='left', on=['user_id', 'merchant_id'],\n",
    ").merge(\n",
    "    df_user_merchant_rf_3, how='left', on=['user_id', 'merchant_id'],\n",
    ")\n",
    "log_print('df_user_merchant_rf shape:', df_user_merchant_rf.shape)\n",
    "del df_user_merchant_rf_0, df_user_merchant_rf_1, df_user_merchant_rf_2, df_user_merchant_rf_3,\n",
    "# 计算 merchant_id 特征\n",
    "df_merchant = df_user_log.groupby('merchant_id').agg(\n",
    "    r_m=('recency', 'min'),\n",
    "    f_m=('user_id', 'count'),\n",
    "    f_user_m=('user_id', 'nunique'),\n",
    "    f_item_m=('item_id', 'nunique'),\n",
    "    f_cat_m=('cat_id', 'nunique'),\n",
    "    f_brand_m=('brand_id', 'nunique'),\n",
    ").reset_index()\n",
    "log_print('df_merchant shape:', df_merchant.shape)\n",
    "df_merchant_0 = df_user_log.query('\"0\"==action_type').groupby('merchant_id').agg(\n",
    "    r_m_0=('recency', 'min'),\n",
    "    f_m_0=('user_id', 'count'),\n",
    "    f_user_m_0=('user_id', 'nunique'),\n",
    "    f_item_m_0=('item_id', 'nunique'),\n",
    "    f_cat_m_0=('cat_id', 'nunique'),\n",
    "    f_brand_m_0=('brand_id', 'nunique'),\n",
    ").reset_index()\n",
    "log_print('df_merchant_0 shape:', df_merchant_0.shape)\n",
    "df_merchant_1 = df_user_log.query('\"1\"==action_type').groupby('merchant_id').agg(\n",
    "    r_m_1=('recency', 'min'),\n",
    "    f_m_1=('user_id', 'count'),\n",
    "    f_user_m_1=('user_id', 'nunique'),\n",
    "    f_item_m_1=('item_id', 'nunique'),\n",
    "    f_cat_m_1=('cat_id', 'nunique'),\n",
    "    f_brand_m_1=('brand_id', 'nunique'),    \n",
    ").reset_index()\n",
    "log_print('df_merchant_1 shape:', df_merchant_1.shape)\n",
    "df_merchant_2 = df_user_log.query('\"2\"==action_type').groupby('merchant_id').agg(\n",
    "    r_m_2=('recency', 'min'),\n",
    "    f_m_2=('user_id', 'count'),\n",
    "    f_user_m_2=('user_id', 'nunique'),\n",
    "    f_item_m_2=('item_id', 'nunique'),\n",
    "    f_cat_m_2=('cat_id', 'nunique'),\n",
    "    f_brand_m_2=('brand_id', 'nunique'),    \n",
    ").reset_index()\n",
    "log_print('df_merchant_2 shape:', df_merchant_2.shape)\n",
    "df_merchant_3 = df_user_log.query('\"3\"==action_type').groupby('merchant_id').agg(\n",
    "    r_m_3=('recency', 'min'),\n",
    "    f_m_3=('user_id', 'count'),\n",
    "    f_user_m_3=('user_id', 'nunique'),\n",
    "    f_item_m_3=('item_id', 'nunique'),\n",
    "    f_cat_m_3=('cat_id', 'nunique'),\n",
    "    f_brand_m_3=('brand_id', 'nunique'),\n",
    ").reset_index()\n",
    "log_print('df_merchant_3 shape:', df_merchant_3.shape)\n",
    "df_merchant = pd.merge(df_merchant, df_merchant_0, on='merchant_id', how='left')\n",
    "df_merchant = pd.merge(df_merchant, df_merchant_1, on='merchant_id', how='left')\n",
    "df_merchant = pd.merge(df_merchant, df_merchant_2, on='merchant_id', how='left')\n",
    "df_merchant = pd.merge(df_merchant, df_merchant_3, on='merchant_id', how='left')\n",
    "log_print('df_merchant shape:', df_merchant.shape)\n",
    "del df_merchant_0, df_merchant_1, df_merchant_2, df_merchant_3,\n",
    "df_user_rf.to_parquet(path +'user_rf.parquet')\n",
    "df_user_merchant_rf.to_parquet(path +'user_merchant_rf.parquet')\n",
    "df_merchant.to_parquet(path +'merchant.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11bd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f6936ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_infer = pd.read_csv(path + 'sample_submission.csv')\n",
    "# # 简单的预测，随机大于0小于1的小数，比如0.5、0.8，均值0.2\n",
    "# df_infer['prob'] = np.random.rand(len(df_infer))\n",
    "# # 保存结果到prediction.csv文件中\n",
    "# df_infer.to_csv(path + 'prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eebacd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xk/njww8w8d7_56yzx17rd8c3rr0000gn/T/ipykernel_69107/2037182088.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[cols_f].fillna(0, inplace=True)\n",
      "/var/folders/xk/njww8w8d7_56yzx17rd8c3rr0000gn/T/ipykernel_69107/2037182088.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[cols_f].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_user_rf = pd.read_parquet(path +'user_rf.parquet')\n",
    "df_user_merchant_rf = pd.read_parquet(path +'user_merchant_rf.parquet')\n",
    "df_merchant = pd.read_parquet(path +'merchant.parquet')\n",
    "\n",
    "df_train = df_train_1.merge(\n",
    "    df_user_info, on='user_id', how='left',\n",
    ").merge(\n",
    "    df_user_merchant_rf, on=['user_id', 'merchant_id'], how='left',\n",
    ").merge(\n",
    "    df_user_rf, on='user_id', how='left',\n",
    ").merge(\n",
    "    df_merchant, on='merchant_id', how='left',\n",
    ")\n",
    "df_train['gender'] = df_train['gender'].astype(str)\n",
    "\n",
    "df_test = df_test_1.merge(\n",
    "    df_user_info, on='user_id', how='left',\n",
    ").merge(\n",
    "    df_user_merchant_rf, on=['user_id', 'merchant_id'], how='left',\n",
    ").merge(\n",
    "    df_user_rf, on='user_id', how='left',\n",
    ").merge(\n",
    "    df_merchant, on='merchant_id', how='left',\n",
    ")\n",
    "df_test['gender'] = df_test['gender'].astype(str)\n",
    "# 将所有的f开头字段缺失补零 \n",
    "cols_f = [\n",
    "    'f', 'f_item', 'f_cat', 'f_merchant', 'f_brand',\n",
    "    'f_0', 'f_item_0', 'f_cat_0', 'f_merchant_0', 'f_brand_0',\n",
    "    'f_1', 'f_item_1', 'f_cat_1', 'f_merchant_1', 'f_brand_1',\n",
    "    'f_2', 'f_item_2', 'f_cat_2', 'f_merchant_2', 'f_brand_2',\n",
    "    'f_3', 'f_item_3', 'f_cat_3', 'f_merchant_3', 'f_brand_3',\n",
    "    'f_um', 'f_item_um', 'f_cat_um', 'f_brand_um',\n",
    "    'f_um_0', 'f_item_um_0', 'f_cat_um_0', 'f_brand_um_0',\n",
    "    'f_um_1', 'f_item_um_1', 'f_cat_um_1', 'f_brand_um_1',\n",
    "    'f_um_2', 'f_item_um_2', 'f_cat_um_2', 'f_brand_um_2',\n",
    "    'f_um_3', 'f_item_um_3', 'f_cat_um_3', 'f_brand_um_3',  \n",
    "    'f_m', 'f_user_m', 'f_item_m', 'f_cat_m', 'f_brand_m',\n",
    "    'f_m_0', 'f_user_m_0', 'f_item_m_0', 'f_cat_m_0', 'f_brand_m_0',\n",
    "    'f_m_1', 'f_user_m_1', 'f_item_m_1', 'f_cat_m_1', 'f_brand_m_1',\n",
    "    'f_m_2', 'f_user_m_2', 'f_item_m_2', 'f_cat_m_2', 'f_brand_m_2',\n",
    "    'f_m_3', 'f_user_m_3', 'f_item_m_3', 'f_cat_m_3', 'f_brand_m_3',   \n",
    "]\n",
    "df_train[cols_f].fillna(0, inplace=True)\n",
    "df_test[cols_f].fillna(0, inplace=True)\n",
    "for i in range(4):\n",
    "    for col in ['', '_item', '_cat', '_merchant', '_brand']:\n",
    "        df_train[f'fp{col}_{i}'] = df_train[f'f{col}_{i}'] / (df_train[f'f{col}'] + 1e-5)\n",
    "        df_test[f'fp{col}_{i}'] = df_test[f'f{col}_{i}'] / (df_test[f'f{col}'] + 1e-5)\n",
    "    for col in ['', '_item', '_cat', '_brand']:\n",
    "        df_train[f'fp{col}_um_{i}'] = df_train[f'f{col}_um_{i}'] / (df_train[f'f{col}_um'] + 1e-5)\n",
    "        df_test[f'fp{col}_um_{i}'] = df_test[f'f{col}_um_{i}'] / (df_test[f'f{col}_um'] + 1e-5)\n",
    "    for col in ['', '_user', '_item', '_cat', '_brand']:\n",
    "        df_train[f'fp{col}_m_{i}'] = df_train[f'f{col}_m_{i}'] / (df_train[f'f{col}_m'] + 1e-5)\n",
    "        df_test[f'fp{col}_m_{i}'] = df_test[f'f{col}_m_{i}'] / (df_test[f'f{col}_m'] + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed8b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7929b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5531294\tbest: 0.5531294 (0)\ttotal: 114ms\tremaining: 18m 59s\n",
      "100:\ttest: 0.6345947\tbest: 0.6346500 (99)\ttotal: 6.57s\tremaining: 10m 44s\n",
      "200:\ttest: 0.6470507\tbest: 0.6470507 (200)\ttotal: 12.7s\tremaining: 10m 17s\n",
      "300:\ttest: 0.6574444\tbest: 0.6574444 (300)\ttotal: 19.1s\tremaining: 10m 14s\n",
      "400:\ttest: 0.6641674\tbest: 0.6641674 (400)\ttotal: 25.3s\tremaining: 10m 4s\n",
      "500:\ttest: 0.6680875\tbest: 0.6680875 (500)\ttotal: 31.4s\tremaining: 9m 55s\n",
      "600:\ttest: 0.6705589\tbest: 0.6705677 (598)\ttotal: 37.5s\tremaining: 9m 47s\n",
      "700:\ttest: 0.6728902\tbest: 0.6728902 (700)\ttotal: 43.8s\tremaining: 9m 41s\n",
      "800:\ttest: 0.6749333\tbest: 0.6749333 (800)\ttotal: 50s\tremaining: 9m 34s\n",
      "900:\ttest: 0.6764788\tbest: 0.6764788 (900)\ttotal: 56.1s\tremaining: 9m 27s\n",
      "1000:\ttest: 0.6776996\tbest: 0.6777029 (998)\ttotal: 1m 2s\tremaining: 9m 19s\n",
      "1100:\ttest: 0.6789024\tbest: 0.6789024 (1100)\ttotal: 1m 8s\tremaining: 9m 11s\n",
      "1200:\ttest: 0.6799081\tbest: 0.6799180 (1198)\ttotal: 1m 14s\tremaining: 9m 4s\n",
      "1300:\ttest: 0.6808309\tbest: 0.6808348 (1299)\ttotal: 1m 20s\tremaining: 8m 57s\n",
      "1400:\ttest: 0.6818386\tbest: 0.6818386 (1400)\ttotal: 1m 26s\tremaining: 8m 50s\n",
      "1500:\ttest: 0.6826197\tbest: 0.6826420 (1498)\ttotal: 1m 33s\tremaining: 8m 47s\n",
      "1600:\ttest: 0.6832793\tbest: 0.6832933 (1586)\ttotal: 1m 39s\tremaining: 8m 39s\n",
      "1700:\ttest: 0.6839885\tbest: 0.6839885 (1700)\ttotal: 1m 45s\tremaining: 8m 33s\n",
      "1800:\ttest: 0.6846327\tbest: 0.6846327 (1800)\ttotal: 1m 51s\tremaining: 8m 26s\n",
      "1900:\ttest: 0.6851492\tbest: 0.6851492 (1900)\ttotal: 1m 57s\tremaining: 8m 19s\n",
      "2000:\ttest: 0.6854710\tbest: 0.6854754 (1998)\ttotal: 2m 3s\tremaining: 8m 12s\n",
      "2100:\ttest: 0.6857507\tbest: 0.6857546 (2098)\ttotal: 2m 9s\tremaining: 8m 5s\n",
      "2200:\ttest: 0.6858373\tbest: 0.6858588 (2178)\ttotal: 2m 15s\tremaining: 7m 58s\n",
      "2300:\ttest: 0.6861594\tbest: 0.6861594 (2300)\ttotal: 2m 21s\tremaining: 7m 52s\n",
      "2400:\ttest: 0.6863459\tbest: 0.6863459 (2400)\ttotal: 2m 27s\tremaining: 7m 45s\n",
      "2500:\ttest: 0.6865375\tbest: 0.6865601 (2494)\ttotal: 2m 33s\tremaining: 7m 38s\n",
      "2600:\ttest: 0.6866473\tbest: 0.6866610 (2580)\ttotal: 2m 39s\tremaining: 7m 32s\n",
      "2700:\ttest: 0.6868806\tbest: 0.6868806 (2700)\ttotal: 2m 45s\tremaining: 7m 26s\n",
      "2800:\ttest: 0.6871088\tbest: 0.6871159 (2795)\ttotal: 2m 51s\tremaining: 7m 19s\n",
      "2900:\ttest: 0.6873924\tbest: 0.6873968 (2899)\ttotal: 2m 57s\tremaining: 7m 13s\n",
      "3000:\ttest: 0.6874529\tbest: 0.6874945 (2977)\ttotal: 3m 3s\tremaining: 7m 7s\n",
      "3100:\ttest: 0.6874604\tbest: 0.6875026 (3020)\ttotal: 3m 9s\tremaining: 7m 1s\n",
      "3200:\ttest: 0.6874313\tbest: 0.6875026 (3020)\ttotal: 3m 15s\tremaining: 6m 56s\n",
      "3300:\ttest: 0.6873680\tbest: 0.6875026 (3020)\ttotal: 3m 22s\tremaining: 6m 50s\n",
      "3400:\ttest: 0.6874871\tbest: 0.6875099 (3390)\ttotal: 3m 28s\tremaining: 6m 44s\n",
      "3500:\ttest: 0.6875331\tbest: 0.6875594 (3494)\ttotal: 3m 34s\tremaining: 6m 38s\n",
      "3600:\ttest: 0.6875019\tbest: 0.6876059 (3527)\ttotal: 3m 40s\tremaining: 6m 32s\n",
      "3700:\ttest: 0.6876100\tbest: 0.6876169 (3696)\ttotal: 3m 46s\tremaining: 6m 25s\n",
      "3800:\ttest: 0.6876473\tbest: 0.6876758 (3759)\ttotal: 3m 52s\tremaining: 6m 19s\n",
      "3900:\ttest: 0.6877416\tbest: 0.6877576 (3897)\ttotal: 3m 58s\tremaining: 6m 13s\n",
      "4000:\ttest: 0.6878274\tbest: 0.6878460 (3988)\ttotal: 4m 4s\tremaining: 6m 7s\n",
      "4100:\ttest: 0.6877999\tbest: 0.6878707 (4021)\ttotal: 4m 10s\tremaining: 6m\n",
      "4200:\ttest: 0.6877945\tbest: 0.6878707 (4021)\ttotal: 4m 16s\tremaining: 5m 54s\n",
      "4300:\ttest: 0.6877562\tbest: 0.6878707 (4021)\ttotal: 4m 22s\tremaining: 5m 48s\n",
      "4400:\ttest: 0.6877573\tbest: 0.6878707 (4021)\ttotal: 4m 28s\tremaining: 5m 42s\n",
      "4500:\ttest: 0.6878830\tbest: 0.6878847 (4497)\ttotal: 4m 35s\tremaining: 5m 36s\n",
      "4600:\ttest: 0.6879683\tbest: 0.6879807 (4598)\ttotal: 4m 41s\tremaining: 5m 29s\n",
      "4700:\ttest: 0.6880584\tbest: 0.6880584 (4700)\ttotal: 4m 47s\tremaining: 5m 23s\n",
      "4800:\ttest: 0.6881584\tbest: 0.6882015 (4780)\ttotal: 4m 53s\tremaining: 5m 17s\n",
      "4900:\ttest: 0.6881422\tbest: 0.6882015 (4780)\ttotal: 4m 59s\tremaining: 5m 11s\n",
      "5000:\ttest: 0.6882647\tbest: 0.6882647 (5000)\ttotal: 5m 5s\tremaining: 5m 5s\n",
      "5100:\ttest: 0.6883018\tbest: 0.6883121 (5077)\ttotal: 5m 11s\tremaining: 4m 59s\n",
      "5200:\ttest: 0.6883578\tbest: 0.6883578 (5200)\ttotal: 5m 17s\tremaining: 4m 52s\n",
      "5300:\ttest: 0.6883708\tbest: 0.6884249 (5267)\ttotal: 5m 23s\tremaining: 4m 46s\n",
      "5400:\ttest: 0.6883950\tbest: 0.6884249 (5267)\ttotal: 5m 29s\tremaining: 4m 40s\n",
      "5500:\ttest: 0.6883308\tbest: 0.6884249 (5267)\ttotal: 5m 35s\tremaining: 4m 34s\n",
      "5600:\ttest: 0.6882955\tbest: 0.6884249 (5267)\ttotal: 5m 41s\tremaining: 4m 28s\n",
      "5700:\ttest: 0.6883541\tbest: 0.6884249 (5267)\ttotal: 5m 47s\tremaining: 4m 22s\n",
      "5800:\ttest: 0.6882434\tbest: 0.6884249 (5267)\ttotal: 5m 53s\tremaining: 4m 15s\n",
      "5900:\ttest: 0.6882729\tbest: 0.6884249 (5267)\ttotal: 5m 59s\tremaining: 4m 9s\n",
      "6000:\ttest: 0.6881748\tbest: 0.6884249 (5267)\ttotal: 6m 5s\tremaining: 4m 3s\n",
      "6100:\ttest: 0.6881618\tbest: 0.6884249 (5267)\ttotal: 6m 11s\tremaining: 3m 57s\n",
      "6200:\ttest: 0.6880316\tbest: 0.6884249 (5267)\ttotal: 6m 17s\tremaining: 3m 51s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 0.688424886\n",
      "bestIteration = 5267\n",
      "\n",
      "Shrink model to first 5268 iterations.\n",
      "/Users/mingjue/downloads/prediction.csv saved!\n"
     ]
    }
   ],
   "source": [
    "# df_train catboost 二分类 训练推理\n",
    "# 固定随机种子，保证结果可复现\n",
    "np.random.seed(42)\n",
    "# 训练代码 \n",
    "from catboost import CatBoostClassifier, Pool  \n",
    "from sklearn.model_selection import train_test_split\n",
    "features = [\n",
    "    'age_range', 'gender',\n",
    "    'r', 'f', 'f_item', 'f_cat', 'f_merchant', 'f_brand',\n",
    "    'r_0', 'f_0', 'f_item_0', 'f_cat_0', 'f_merchant_0', 'f_brand_0', 'fp_0', 'fp_item_0', 'fp_cat_0', 'fp_merchant_0', 'fp_brand_0',\n",
    "    'r_1', 'f_1', 'f_item_1', 'f_cat_1', 'f_merchant_1', 'f_brand_1', 'fp_1', 'fp_item_1', 'fp_cat_1', 'fp_merchant_1', 'fp_brand_1',\n",
    "    'r_2', 'f_2', 'f_item_2', 'f_cat_2', 'f_merchant_2', 'f_brand_2', 'fp_2', 'fp_item_2', 'fp_cat_2', 'fp_merchant_2', 'fp_brand_2',\n",
    "    'r_3', 'f_3', 'f_item_3', 'f_cat_3', 'f_merchant_3', 'f_brand_3', 'fp_3', 'fp_item_3', 'fp_cat_3', 'fp_merchant_3', 'fp_brand_3',\n",
    "    'r_um', 'f_um', 'f_item_um', 'f_cat_um', 'f_brand_um',\n",
    "    'r_um_0', 'f_um_0', 'f_item_um_0', 'f_cat_um_0', 'f_brand_um_0', 'fp_um_0', 'fp_item_um_0', 'fp_cat_um_0', 'fp_brand_um_0',\n",
    "    'r_um_1', 'f_um_1', 'f_item_um_1', 'f_cat_um_1', 'f_brand_um_1', 'fp_um_1', 'fp_item_um_1', 'fp_cat_um_1', 'fp_brand_um_1',\n",
    "    'r_um_2', 'f_um_2', 'f_item_um_2', 'f_cat_um_2', 'f_brand_um_2', 'fp_um_2', 'fp_item_um_2', 'fp_cat_um_2', 'fp_brand_um_2',\n",
    "    'r_um_3', 'f_um_3', 'f_item_um_3', 'f_cat_um_3', 'f_brand_um_3', 'fp_um_3', 'fp_item_um_3', 'fp_cat_um_3', 'fp_brand_um_3',\n",
    "    'r_m', 'f_m', 'f_user_m', 'f_item_m', 'f_cat_m', 'f_brand_m',\n",
    "    'r_m_0', 'f_m_0', 'f_user_m_0', 'f_item_m_0', 'f_cat_m_0', 'f_brand_m_0', 'fp_m_0', 'fp_user_m_0', 'fp_item_m_0', 'fp_cat_m_0', 'fp_brand_m_0',\n",
    "    'r_m_1', 'f_m_1', 'f_user_m_1', 'f_item_m_1', 'f_cat_m_1', 'f_brand_m_1', 'fp_m_1', 'fp_user_m_1', 'fp_item_m_1', 'fp_cat_m_1', 'fp_brand_m_1',\n",
    "    'r_m_2', 'f_m_2', 'f_user_m_2', 'f_item_m_2', 'f_cat_m_2', 'f_brand_m_2', 'fp_m_2', 'fp_user_m_2', 'fp_item_m_2', 'fp_cat_m_2', 'fp_brand_m_2',\n",
    "    'r_m_3', 'f_m_3', 'f_user_m_3', 'f_item_m_3', 'f_cat_m_3', 'f_brand_m_3', 'fp_m_3', 'fp_user_m_3', 'fp_item_m_3', 'fp_cat_m_3', 'fp_brand_m_3',\n",
    "]\n",
    "target = 'label'\n",
    "X = df_train[features]\n",
    "y = df_train[target].astype(float)\n",
    "X_test = df_test[features]        \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_pool = Pool(X_train, y_train, cat_features=['gender'])\n",
    "val_pool = Pool(X_val, y_val, cat_features=['gender'])  \n",
    "model = CatBoostClassifier(iterations=10000, learning_rate=0.01, depth=6, eval_metric='AUC', random_seed=42, logging_level='Verbose', use_best_model=True)\n",
    "model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=1000, verbose=100)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "df_test['prob'] = y_pred\n",
    "df_test[['user_id', 'merchant_id', 'prob']].to_csv(path + 'prediction.csv', index=False)  \n",
    "print(path + 'prediction.csv saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5100:\ttest: 0.6858243\tbest: 0.6858491 (5074)\ttotal: 4m 30s\tremaining: 4m 20s\n",
    "# 5200:\ttest: 0.6859037\tbest: 0.6859302 (5178)\ttotal: 4m 36s\tremaining: 4m 14s\n",
    "# 5300:\ttest: 0.6858344\tbest: 0.6859302 (5178)\ttotal: 4m 41s\tremaining: 4m 9s\n",
    "# 5400:\ttest: 0.6858755\tbest: 0.6859302 (5178)\ttotal: 4m 46s\tremaining: 4m 4s\n",
    "# 5500:\ttest: 0.6858226\tbest: 0.6859302 (5178)\ttotal: 4m 51s\tremaining: 3m 58s\n",
    "# 5600:\ttest: 0.6857450\tbest: 0.6859302 (5178)\ttotal: 4m 57s\tremaining: 3m 53s\n",
    "# Stopped by overfitting detector  (500 iterations wait)\n",
    "\n",
    "# bestTest = 0.6859301753\n",
    "# bestIteration = 5178\n",
    "\n",
    "# Shrink model to first 5179 iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
